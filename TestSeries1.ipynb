{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da10ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "def dummy_tests(X_train, X_test, y_train, y_test):\n",
    "    print(\"Dummy Tests Started\")\n",
    "    \n",
    "    # List of strategies to test\n",
    "    strategies = [\"stratified\", \"most_frequent\", \"uniform\"]\n",
    "\n",
    "    # Loop through each strategy\n",
    "    for strategy in strategies:\n",
    "        dummy_clf = DummyClassifier(strategy=strategy)\n",
    "        dummy_clf.fit(X_train, y_train)\n",
    "        results = evaluate_model(dummy_clf, X_test, y_test)\n",
    "        dl.save_info(dummy_clf, results)\n",
    "\n",
    "    print(\"Dummy Tests Complete\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3214fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model \n",
    "\n",
    "def lin_tests(X_train, X_test, y_train, y_test):\n",
    "    print(\"Linear Tests Started\")\n",
    "\n",
    "    # Models configuration\n",
    "    models = [\n",
    "        linear_model.LinearRegression(),\n",
    "        linear_model.Ridge(alpha=0.5),\n",
    "        linear_model.Lasso(alpha=0.1),\n",
    "        linear_model.MultiTaskLasso(alpha=0.1),\n",
    "        linear_model.Lars(n_nonzero_coefs=1),\n",
    "        linear_model.LassoLars(alpha=0.1)\n",
    "    ]\n",
    "\n",
    "    # Loop through each model\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        results = evaluate_model(model, X_test, y_test)\n",
    "        dl.save_info(str(model), results)\n",
    "\n",
    "    print(\"Linear Tests Complete\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bede4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def complex_tests(X_train, X_test, y_train, y_test):\n",
    "    print(\"Complex Tests Begin\")\n",
    "  \n",
    "    # Models configuration\n",
    "    models = [\n",
    "        DecisionTreeClassifier(random_state=0),\n",
    "        ExtraTreesClassifier(),\n",
    "        KNeighborsClassifier(algorithm='kd_tree'),\n",
    "        RandomForestClassifier(max_depth=None, random_state=0)\n",
    "    ]\n",
    "\n",
    "    # Loop through each model\n",
    "    for model in models:\n",
    "        print(f\"Testing model: {type(model).__name__}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        results = evaluate_model(model, X_test, y_test)\n",
    "        dl.save_info(str(model), results)\n",
    "    print(\"Complex Tests Complete\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e93b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def ML_Tests(X_train, X_test, y_train, y_test):\n",
    "    print(\"Multi Layer Perceptron Tests Begin\")\n",
    "  \n",
    "    # Models configuration\n",
    "    models = [\n",
    "        MLPClassifier(hidden_layer_sizes=(1024), max_iter=1000),\n",
    "        MLPClassifier(hidden_layer_sizes=(2048), max_iter=1000),\n",
    "        MLPClassifier(hidden_layer_sizes=(512,512), max_iter=1000),\n",
    "        MLPClassifier(hidden_layer_sizes=(1024,1024), max_iter=1000)\n",
    "    ]\n",
    "\n",
    "    # Loop through each model\n",
    "    for model in models:\n",
    "        print(f\"Testing model: {type(model).__name__}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        results = evaluate_model(model, X_test, y_test)\n",
    "        dl.save_info(str(model), results)\n",
    "    print(\"Multi Layer Perceptron Complete\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58180792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def KNeighbors_Tests(X_train, X_test, y_train, y_test):\n",
    "    print(\"K Neighbors Tests Begin\")\n",
    "  \n",
    "    # Models configuration\n",
    "    models = [\n",
    "        KNeighborsClassifier(weights='distance'),\n",
    "    ]\n",
    "\n",
    "    # Loop through each model\n",
    "    for model in models:\n",
    "        print(f\"Testing model: {type(model).__name__}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        results = evaluate_model(model, X_test, y_test)\n",
    "        dl.save_info(str(model), results)\n",
    "    print(\"K Neighbors Complete\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eafac572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def Forest_Tests(X_train, X_test, y_train, y_test):\n",
    "    print(\"Random Forest Tests Begin\")\n",
    "  \n",
    "    # Models configuration\n",
    "    models = [\n",
    "        #RandomForestClassifier(n_estimators=2, max_depth=None, bootstrap=True, random_state=0),\n",
    "        #RandomForestClassifier(n_estimators=4, max_depth=None, bootstrap=True, random_state=0),\n",
    "        #RandomForestClassifier(n_estimators=8, max_depth=None, bootstrap=True, random_state=0),\n",
    "        #RandomForestClassifier(n_estimators=16,max_depth=None, bootstrap=True, random_state=0),\n",
    "        #RandomForestClassifier(n_estimators=32,max_depth=None, bootstrap=True, random_state=0),\n",
    "        RandomForestClassifier(n_estimators=64,max_depth=None, bootstrap=True, random_state=0),\n",
    "        RandomForestClassifier(n_estimators=128,max_depth=None, bootstrap=True, random_state=0),\n",
    "        RandomForestClassifier(n_estimators=256,max_depth=None, bootstrap=True, random_state=0),\n",
    "        #RandomForestClassifier(n_estimators=512,max_depth=None, bootstrap=True, random_state=0),\n",
    "        #RandomForestClassifier(n_estimators=1024,max_depth=None, bootstrap=True, random_state=0)\n",
    "    ]\n",
    "\n",
    "    # Loop through each model\n",
    "    for model in models:\n",
    "        print(f\"Testing model: {type(model).__name__}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        results = evaluate_model(model, X_test, y_test)\n",
    "        dl.save_info(str(model), results)\n",
    "    print(\"Random Forest Tests Complete\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf3fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Test Series 1\n",
      "Input Size: 90\n",
      "Stocks: 1\n",
      "Data Already Exists: Now Loading\n",
      "Data Loaded: Running Tests \n",
      "\n",
      "90\n",
      "Dummy Tests Started\n",
      "Testing with strategy: stratified\n",
      "Testing with strategy: most_frequent\n",
      "Testing with strategy: uniform\n",
      "Dummy Tests Complete\n",
      "\n",
      "Linear Tests Started\n",
      "Testing model: LinearRegression\n",
      "Testing model: Ridge\n",
      "Testing model: Lasso\n",
      "Testing model: MultiTaskLasso\n",
      "Testing model: Lars\n",
      "Testing model: LassoLars\n",
      "Linear Tests Complete\n",
      "\n",
      "Complex Tests Begin\n",
      "Testing model: DecisionTreeClassifier\n",
      "Testing model: ExtraTreesClassifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import yfinance\n",
    "import torch\n",
    "# Columns saved for later\n",
    "#Small Feature List (Default Stock Info)\n",
    "features = ['Date','Close', 'High', 'Low', 'Open', 'Volume', \n",
    "                 'volume_obv', 'volume_cmf', 'volume_fi', 'volume_em', \n",
    "                 'volume_sma_em', 'volume_vpt', 'volume_vwap', 'volume_mfi', 'volume_nvi',\n",
    "                 'volatility_bbm','volatility_bbh','volatility_bbl','volatility_bbw',\n",
    "                 'volatility_bbp','volatility_bbhi','volatility_bbli','volatility_kcc',\n",
    "                 'volatility_kcl','volatility_kcw','volatility_kcp','volatility_kchi',\n",
    "                 'volatility_kcli','volatility_dcl','volatility_dch','volatility_dcm',\n",
    "                 'volatility_dcw','volatility_dcp','volatility_atr','volatility_ui',\n",
    "                 'trend_macd','trend_macd_signal','trend_macd_diff', 'trend_sma_fast',\n",
    "                 'trend_sma_slow','trend_ema_fast', 'trend_ema_slow','trend_vortex_ind_pos',\n",
    "                 'trend_vortex_ind_neg','trend_vortex_ind_diff','trend_trix','trend_mass_index',\n",
    "                 'trend_dpo','trend_kst','trend_kst_sig','trend_kst_diff','trend_ichimoku_conv',\n",
    "                 'trend_ichimoku_base','trend_ichimoku_a','trend_ichimoku_b','trend_stc',\n",
    "                 'trend_adx','trend_adx_pos','trend_adx_neg','trend_cci','trend_visual_ichimoku_a',\n",
    "                 'trend_visual_ichimoku_b','trend_aroon_up','trend_aroon_down','trend_aroon_ind',\n",
    "                 'trend_psar_up','trend_psar_down','trend_psar_up_indicator','trend_psar_down_indicator',\n",
    "                 'momentum_rsi','momentum_stoch_rsi','momentum_stoch_rsi_k','momentum_stoch_rsi_d',\n",
    "                 'momentum_tsi','momentum_uo','momentum_stoch','momentum_stoch_signal',\n",
    "                 'momentum_wr','momentum_ao','momentum_roc','momentum_ppo','momentum_ppo_signal',\n",
    "                 'momentum_ppo_hist','momentum_pvo','momentum_pvo_signal','momentum_pvo_hist',\n",
    "                 'momentum_kama','others_dr','others_dlr','others_cr']\n",
    "#Processed Default Stock Info\n",
    "\n",
    "\n",
    "input_size = len(features)\n",
    "output_size = 10\n",
    "stocks = 1\n",
    "#stock amount, this works but it takes a while\n",
    "\n",
    "print(\"Starting Test Series 1\")\n",
    "print(f\"Input Size: {input_size}\")\n",
    "print(f\"Stocks: {stocks}\")\n",
    "\n",
    "%run ./Helpers.ipynb\n",
    "\n",
    "pre_ticker = filter_companies(\"companies.csv\",stocks)[\"Symbol\"]\n",
    "if os.path.exists('data.csv'):\n",
    "    # Load the file into a DataFrame\n",
    "    print(\"Data Already Exists: Now Loading\")\n",
    "    X,y = prepare_dataset('data.csv', features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "else:\n",
    "    preprocessed_data = preprocess1(pre_ticker,output_size)\n",
    "    print(\"Data Created: Now Loading\")\n",
    "    X,y = prepare_dataset('data.csv', features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    print(\"Data Split: Now Running Tests\")\n",
    "print(\"Data Loaded: Running Tests \")\n",
    "print()\n",
    "\n",
    "# Get the size of the file in bytes\n",
    "file_size_bytes = os.path.getsize(\"data.csv\")\n",
    "# Convert the size from bytes to megabytes\n",
    "data_size = round(file_size_bytes / (1024 * 1024))\n",
    "\n",
    "dl = datalogger(input_size,data_size, output_size, stocks)\n",
    "\n",
    "\n",
    "dummy_tests(X_train, X_test, y_train, y_test)\n",
    "lin_tests(X_train, X_test, y_train, y_test)\n",
    "complex_tests(X_train, X_test, y_train, y_test)\n",
    "KNeighbors_Tests(X_train, X_test, y_train, y_test)\n",
    "ML_Tests(X_train, X_test, y_train, y_test)\n",
    "Forest_Tests(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195bbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01a60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
