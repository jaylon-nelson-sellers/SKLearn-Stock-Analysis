{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6236d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "def filter_companies(file_name, stocks):\n",
    "    \"\"\"\n",
    "    Filters companies to US only (New York Stock Exchange)\n",
    "\n",
    "    Parameters:\n",
    "    - file_name (str): The name of the CSV file containing company data.\n",
    "    - stocks (int): number of stock tickers to save\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Filtered DataFrame with companies from the United States.\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "    # Fill NaN values in 'country' column with an empty string\n",
    "    df['country'] = df['country'].fillna('')\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    filtered_df = df[df[\"country\"].str.contains(\"United States\")].head(stocks)\n",
    "\n",
    "    # Return the filtered DataFrame\n",
    "    return filtered_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99cc88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicators(df):\n",
    "    \"\"\"\n",
    "    adds 84 Technical Indicators to the dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    - df (dataframe): The dataframe containing default stock information\n",
    "    \n",
    "    Returns: \n",
    "    - Dataframe: the initial dataframe with all Technical Indicators\n",
    "    \n",
    "    \"\"\"\n",
    "    #print(df.shape)\n",
    "    df = dropna(df)\n",
    "    df = add_all_ta_features(\n",
    "        df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9370b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime_to_int(df):\n",
    "    \"\"\"\n",
    "    Converts datetime column to integer format.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame with datetime column.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: DataFrame with datetime converted to int.\n",
    "    \"\"\"\n",
    "    df = df.reset_index()\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Date'] = df['Date'].view('int64') // 10**9  # Converts to seconds\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db292641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df, columns):\n",
    "    \"\"\"\n",
    "    Normalizes specified columns in the DataFrame.\n",
    "    Deletes the old columns once done\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to normalize.\n",
    "    - columns (list): List of column names to normalize.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: DataFrame with normalized columns.\n",
    "    \"\"\"\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    saved_col = []\n",
    "    for col in columns:\n",
    "        saved_col.append(f'n_{col}')\n",
    "        df[f'n_{col}'] = scaler.fit_transform(df[[col]])\n",
    "        df = df.drop(col, axis=1)\n",
    "    return [df,saved_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "971ed222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_profit(df, days):\n",
    "    \"\"\"\n",
    "    Creates buy and profit target columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame.\n",
    "    - days (int): The number of days to calculate profit.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: DataFrame with profit columns.\n",
    "    \"\"\"\n",
    "    for day in range(1, days+1):\n",
    "        future_close = df['Close'].shift(-day)\n",
    "        current_close = df['Close']\n",
    "\n",
    "        # Calculate buy signal\n",
    "        df['T1-Buy-' + str(day) + 'D'] = (future_close > current_close).astype(int)\n",
    "\n",
    "        # Calculate profit ratio and handle non-finite values\n",
    "        profit_ratio = future_close / current_close\n",
    "        profit_ratio[~np.isfinite(profit_ratio)] = 0  # Replace non-finite values with 0\n",
    "        df['T2-Profit-' + str(day) + 'D'] = profit_ratio.astype(float)\n",
    "\n",
    "    # Drop the last 'days' rows to avoid NaNs in the shifted columns\n",
    "    df.drop(df.tail(days).index, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def save_temp_csv(df, filename='temp.csv'):\n",
    "    \"\"\"\n",
    "    Saves the DataFrame to a temporary CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to save.\n",
    "    - filename (str, optional): The filename to save as. Defaults to 'temp.csv'.\n",
    "    \"\"\"\n",
    "    df.to_csv(os.path.join(os.getcwd(), filename), index=False)\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e70f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess(stocks, day, chunk_size=10000):\n",
    "    \"\"\"\n",
    "    Preprocesses the data from the given filepath.\n",
    "\n",
    "    Parameters:\n",
    "    - stocks (list): List of stock tickers.\n",
    "    - x_columns (list): List of columns to normalize.\n",
    "    - day (int): The number of days to calculate profit.\n",
    "    - chunk_size (int): The size of each chunk to process.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Preprocessed data.\n",
    "    \"\"\"\n",
    "    first_chunk = True\n",
    "    for t in stocks:\n",
    "        y = yfinance.Ticker(t)\n",
    "        hist = y.history(period=\"max\")\n",
    "\n",
    "        # Removes unused columns\n",
    "        hist = hist.drop(columns=['Dividends', 'Stock Splits'], errors='ignore')\n",
    "        hist = hist.dropna()\n",
    "\n",
    "        if hist.empty:\n",
    "            continue\n",
    "\n",
    "        # Here's the magic\n",
    "        #hist = add_indicators(hist)\n",
    "        hist = convert_datetime_to_int(hist)\n",
    "        hist = create_profit(hist, day)\n",
    "        hist.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        hist.fillna(0, inplace=True)\n",
    "\n",
    "        # Processing in chunks\n",
    "        for start in range(0, len(hist), chunk_size):\n",
    "            chunk = hist.iloc[start:start+chunk_size]\n",
    "\n",
    "            # Saving chunk to CSV\n",
    "            mode = 'w' if first_chunk else 'a'\n",
    "            header = first_chunk\n",
    "            chunk.to_csv(\"data.csv\", mode=mode, header=header, index=False)\n",
    "            first_chunk = False\n",
    "    \n",
    "    print(\"Preprocessing Done\")\n",
    "    # Read and return the entire preprocessed data\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c333f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data, cols):\n",
    "    # Extracting features and target from the preprocessed data\n",
    "    data = pd.read_csv(data)\n",
    "    norm_data, n_cols = normalize_columns(data, cols)\n",
    "    \n",
    "    X = norm_data[n_cols]\n",
    "    selected_columns = norm_data.filter(regex='T1')\n",
    "    y = selected_columns.to_numpy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd381cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation Methods\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import hamming_loss, mean_squared_error, accuracy_score, mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "sklearn eval method: \n",
    "Uses predict to get test results\n",
    "\"\"\"\n",
    "def evaluate_model(net, X_test, y_test):\n",
    "    prediction = net.predict(X_test)\n",
    "     # Check if X_test and y_test are tensors, and convert them to numpy if they are\n",
    "\n",
    "    # Binarize predictions\n",
    "    prediction_bin = [[1 if element > 0.5 else 0 for element in row] for row in prediction]\n",
    "\n",
    "    # Calculating metrics\n",
    "    ham_loss = hamming_loss(y_test, prediction_bin)\n",
    "    out_acc = round(accuracy_score(y_test, prediction_bin),4)\n",
    "    ham_acc = round(1- ham_loss,4)\n",
    "    mse = round(mean_squared_error(y_test, prediction), 4)\n",
    "\n",
    "    # Print and return results\n",
    "    #printResults(ham_acc, out_acc, mse)\n",
    "    return [out_acc, ham_acc, mse]\n",
    "\n",
    "   \n",
    "\"\"\"prints results\"\"\"\n",
    "def printResults(ham_acc, out_acc, mse):\n",
    "    print(\"Output Accuracy:\", out_acc)\n",
    "    print(\"Individual Accuracy:\", ham_acc)\n",
    "    print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72c35dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class datalogger():\n",
    "    def __init__(self,features,output_size,stocks):\n",
    "        self.init = []\n",
    "        self.init.append(features)\n",
    "        self.init.append(output_size)\n",
    "        self.init.append(stocks)\n",
    "        self.records = []\n",
    "        headers = []\n",
    "        headers.append(\"Features\")\n",
    "        headers.append(\"Output Size\")\n",
    "        headers.append(\"Num of Stocks\")\n",
    "        headers.append(\"Model\")\n",
    "        headers.append(\"Output Accuracy\")\n",
    "        headers.append(\"Individual Accuracy\")\n",
    "        headers.append(\"Mean Square Error\")\n",
    "        self.records.append(headers)\n",
    "\n",
    "    def save_info(self, model, results):\n",
    "        info = []\n",
    "        for i in self.init:\n",
    "            info.append(i)\n",
    "        \n",
    "        info.append(model)\n",
    "        for r in results:\n",
    "            info.append(r)\n",
    "        self.records.append(info)\n",
    "        \n",
    "        df = pd.DataFrame(self.records)\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv('output.csv', index=False, header=False)\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae9d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992e21e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
